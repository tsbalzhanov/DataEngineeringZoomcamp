{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1857ba52-4001-4943-b232-c8351a3da142",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pathlib\n",
    "\n",
    "import pyspark\n",
    "import pyspark.sql.types as ps_types\n",
    "import pyspark.sql.functions as ps_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0aa4d28-0c36-442a-9082-54d4cceaa8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/27 23:19:51 WARN Utils: Your hostname, Tsyrens-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 192.168.0.10 instead (on interface en0)\n",
      "24/02/27 23:19:51 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/02/27 23:19:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = pyspark.sql.SparkSession.builder \\\n",
    "    .master('local[*]') \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96888b86-76c5-481d-84d9-404350562aa7",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89a13808-1269-4042-a7f6-07c016d7bc87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.0\n"
     ]
    }
   ],
   "source": [
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab19de12-21e3-45e7-827c-d84c7d0d2298",
   "metadata": {},
   "source": [
    "### Load FHV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e490d07-a6de-42a8-a569-acf168bdbe52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+--------------+--------------+-------+----------------------+\n",
      "|dispatching_base_num|    pickup_datetime|  drop_off_datetime|pu_location_id|do_location_id|sr_flag|affiliated_base_number|\n",
      "+--------------------+-------------------+-------------------+--------------+--------------+-------+----------------------+\n",
      "|              B00009|2019-10-01 00:23:00|2019-10-01 00:35:00|           264|           264|   NULL|                B00009|\n",
      "|              B00013|2019-10-01 00:11:29|2019-10-01 00:13:22|           264|           264|   NULL|                B00013|\n",
      "|              B00014|2019-10-01 00:11:43|2019-10-01 00:37:20|           264|           264|   NULL|                B00014|\n",
      "|              B00014|2019-10-01 00:56:29|2019-10-01 00:57:47|           264|           264|   NULL|                B00014|\n",
      "|              B00014|2019-10-01 00:23:09|2019-10-01 00:28:27|           264|           264|   NULL|                B00014|\n",
      "|     B00021         |2019-10-01 00:00:48|2019-10-01 00:07:12|           129|           129|   NULL|       B00021         |\n",
      "|     B00021         |2019-10-01 00:47:23|2019-10-01 00:53:25|            57|            57|   NULL|       B00021         |\n",
      "|     B00021         |2019-10-01 00:10:06|2019-10-01 00:19:50|           173|           173|   NULL|       B00021         |\n",
      "|     B00021         |2019-10-01 00:51:37|2019-10-01 01:06:14|           226|           226|   NULL|       B00021         |\n",
      "|     B00021         |2019-10-01 00:28:23|2019-10-01 00:34:33|            56|            56|   NULL|       B00021         |\n",
      "+--------------------+-------------------+-------------------+--------------+--------------+-------+----------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tripdate_file_path = 'data/raw/fhv/2019/10/fhv_tripdata_2019_10.csv.gz'\n",
    "\n",
    "fhv_schema = ps_types.StructType([\n",
    "    ps_types.StructField('dispatching_base_num', ps_types.StringType(), True), \n",
    "    ps_types.StructField('pickup_datetime', ps_types.TimestampType(), True), \n",
    "    ps_types.StructField('dropOff_datetime', ps_types.TimestampType(), True), \n",
    "    ps_types.StructField('PUlocationID', ps_types.IntegerType(), True), \n",
    "    ps_types.StructField('DOlocationID', ps_types.IntegerType(), True), \n",
    "    ps_types.StructField('SR_Flag', ps_types.StringType(), True), \n",
    "    ps_types.StructField('Affiliated_base_number', ps_types.StringType(), True)\n",
    "])\n",
    "\n",
    "df = spark.read \\\n",
    "    .option('header', True) \\\n",
    "    .schema(fhv_schema) \\\n",
    "    .csv(tripdate_file_path)\n",
    "\n",
    "df = df.withColumnsRenamed({\n",
    "    'dropOff_datetime': 'drop_off_datetime',\n",
    "    'PUlocationID': 'pu_location_id',\n",
    "    'DOlocationID': 'do_location_id',\n",
    "    'SR_Flag': 'sr_flag',\n",
    "    'Affiliated_base_number': 'affiliated_base_number'\n",
    "})\n",
    "\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f66300-6db5-4715-8798-7f657c2ddd14",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "927f6706-c76e-4515-80de-67361630ad85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 6) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part-00001-59fc8522-4fb1-4708-997a-fa6c48a744d9-c000.snappy.parquet\n",
      "part-00000-59fc8522-4fb1-4708-997a-fa6c48a744d9-c000.snappy.parquet\n",
      "part-00002-59fc8522-4fb1-4708-997a-fa6c48a744d9-c000.snappy.parquet\n",
      "part-00005-59fc8522-4fb1-4708-997a-fa6c48a744d9-c000.snappy.parquet\n",
      "part-00004-59fc8522-4fb1-4708-997a-fa6c48a744d9-c000.snappy.parquet\n",
      "part-00003-59fc8522-4fb1-4708-997a-fa6c48a744d9-c000.snappy.parquet\n",
      "Average partition size: 6.35MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "partitioned_dir = pathlib.Path('data/transformed/fhv/2019/10')\n",
    "partitioned_dir.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df = df.repartition(6)\n",
    "df.write.parquet(str(partitioned_dir), mode='overwrite')\n",
    "\n",
    "sizes = []\n",
    "for path in partitioned_dir.iterdir():\n",
    "    if not path.name.startswith('.') and path.name != '_SUCCESS':\n",
    "        print(path.name)\n",
    "        sizes.append(path.stat().st_size)\n",
    "avg_size_mb = sum(sizes) / len(sizes) / 2**20\n",
    "print(f'Average partition size: {avg_size_mb:.2f}MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f382813-853f-43e3-8f44-b7f1cd22c3e9",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07aa25ad-8d6e-42ef-9ddb-81730c2471c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "62610"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.withColumn('pickup_date', ps_functions.to_date('pickup_datetime')) \\\n",
    "    .filter(ps_functions.col('pickup_date') == datetime.date(2019, 10, 15))\\\n",
    "    .count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15415b20-de58-4b2d-8c92-eb2d2edc17fc",
   "metadata": {},
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3155909e-22ee-4bab-a3c0-3035369e05be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:>                                                         (0 + 6) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|max(duration)|\n",
      "+-------------+\n",
      "|     631152.5|\n",
      "+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "duration_in_hours_udf = ps_functions.udf(\n",
    "    lambda duration: duration.total_seconds() / (60 * 60),\n",
    "    ps_types.DoubleType()\n",
    ")\n",
    "\n",
    "df.withColumn('duration', df.drop_off_datetime - df.pickup_datetime) \\\n",
    "    .withColumn('duration', duration_in_hours_udf(ps_functions.col('duration'))) \\\n",
    "    .agg({'duration': 'max'}) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dee3fc-e2b4-4aca-b09f-ce0c70abc6e3",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "http://localhost:4040/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a70e1ab-6ada-40df-a6be-382d63efa2fa",
   "metadata": {},
   "source": [
    "### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19c7be28-1e92-4b7f-a425-88654e4a2467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+--------------------+------------+\n",
      "|location_id|      borough|                zone|service_zone|\n",
      "+-----------+-------------+--------------------+------------+\n",
      "|          1|          EWR|      Newark Airport|         EWR|\n",
      "|          2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|          3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|          4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|          5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "|          6|Staten Island|Arrochar/Fort Wad...|   Boro Zone|\n",
      "|          7|       Queens|             Astoria|   Boro Zone|\n",
      "|          8|       Queens|        Astoria Park|   Boro Zone|\n",
      "|          9|       Queens|          Auburndale|   Boro Zone|\n",
      "|         10|       Queens|        Baisley Park|   Boro Zone|\n",
      "+-----------+-------------+--------------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zones_file_path = 'data/raw/taxi_zone_lookup.csv'\n",
    "\n",
    "zones_schema = ps_types.StructType([\n",
    "    ps_types.StructField('LocationID', ps_types.IntegerType(), True), \n",
    "    ps_types.StructField('Borough', ps_types.StringType(), True), \n",
    "    ps_types.StructField('Zone', ps_types.StringType(), True), \n",
    "    ps_types.StructField('service_zone', ps_types.StringType(), True)\n",
    "])\n",
    "\n",
    "zones_df = spark.read \\\n",
    "    .option('header', True) \\\n",
    "    .schema(zones_schema) \\\n",
    "    .csv(zones_file_path)\n",
    "\n",
    "zones_df = zones_df.withColumnsRenamed({\n",
    "    'LocationID': 'location_id',\n",
    "    'Borough': 'borough',\n",
    "    'Zone': 'zone'\n",
    "})\n",
    "\n",
    "zones_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29a71bac-2eef-487a-93e2-9b384932fe84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 17:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|min_by(zone, count)|\n",
      "+-------------------+\n",
      "|        Jamaica Bay|\n",
      "+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.join(zones_df, df.pu_location_id == zones_df.location_id) \\\n",
    "    .groupby(ps_functions.col('zone')) \\\n",
    "    .count() \\\n",
    "    .agg(ps_functions.min_by('zone', 'count')) \\\n",
    "    .show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
